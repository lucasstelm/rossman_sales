{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROSSMAN SALES PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Id - an Id that represents a (Store, Date) duple within the test set\n",
    "* Store - a unique Id for each store\n",
    "* Sales - the turnover for any given day (this is what you are predicting)\n",
    "* Customers - the number of customers on a given day\n",
    "* Open - an indicator for whether the store was open: 0 = closed, 1 = open\n",
    "* StateHoliday - indicates a state holiday. Normally all stores, with few exceptions, are closed on state holidays. Note that all schools are closed on public holidays and weekends. a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
    "* SchoolHoliday - indicates if the (Store, Date) was affected by the closure of public schools\n",
    "* StoreType - differentiates between 4 different store models: a, b, c, d\n",
    "* Assortment - describes an assortment level: a = basic, b = extra, c = extended\n",
    "* CompetitionDistance - distance in meters to the nearest competitor store\n",
    "* CompetitionOpenSince[Month/Year] - gives the approximate year and month of the time the nearest competitor was opened\n",
    "* Promo - indicates whether a store is running a promo on that day\n",
    "* Promo2 - Promo2 is a continuing and consecutive promotion for some stores: 0 = store is not participating, 1 = store is participating\n",
    "* Promo2Since[Year/Week] - describes the year and calendar week when the store started participating in Promo2\n",
    "* PromoInterval - describes the consecutive intervals Promo2 is started, naming the months the promotion is started anew. E.g. \"Feb,May,Aug,Nov\" means each round starts in February, May, August, November of any given year for that store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal encoder on STORE column is OK for Tree Based Models but not so good for Linear Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show a graph for TimeSeriesKFold showing the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "import inflection\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "import missingno as msno\n",
    "\n",
    "from matplotlib            import pyplot as plt\n",
    "from IPython.core.display  import HTML\n",
    "\n",
    "\n",
    "from sklearn.metrics       import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.linear_model  import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import RobustScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.impute        import SimpleImputer\n",
    "from sklearn.pipeline      import Pipeline, make_pipeline \n",
    "from sklearn.compose       import ColumnTransformer, TransformedTargetRegressor, make_column_transformer\n",
    "from sklearn.linear_model  import LinearRegression\n",
    "from sklearn.base          import  BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_regression, mutual_info_regression, RFECV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_predict\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y, y_pred):\n",
    "    return np.mean(np.abs((y - y_pred)/y))\n",
    "\n",
    "    \n",
    "def ml_error(model_name, y, y_pred):\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y, y_pred)\n",
    "    rmse = np.sqrt( mean_squared_error(y, y_pred))\n",
    "    return pd.DataFrame( { 'Model Name': model_name, \n",
    "                           'MAE': mae, \n",
    "                           'MAPE': mape,\n",
    "                           'RMSE': rmse }, index=[0] )\n",
    "\n",
    "def cross_validation(df, kfold, model_name, model, verbose=False):\n",
    "    mae_list = []\n",
    "    mape_list = []\n",
    "    rmse_list = []\n",
    "    for k in reversed(range(1, kfold +1)):\n",
    "        if verbose:\n",
    "            print( '\\nKFold Number: {}'.format( k ) )\n",
    "        # start and end date for validation \n",
    "        validation_start_date = df['Date'].max() - datetime.timedelta(days=k*6*7)\n",
    "        validation_end_date = df['Date'].max() - datetime.timedelta(days=(k-1)*6*7)\n",
    "\n",
    "        # filtering dataset\n",
    "        train = df[df['Date'] < validation_start_date]\n",
    "        test = df[(df['Date'] >= validation_start_date) & (df['Date'] <= validation_end_date)]\n",
    "\n",
    "        # train\n",
    "        X_train = train.drop(['Customers', 'Sales'], axis=1)\n",
    "        y_train = train['Sales']\n",
    "\n",
    "        # validation\n",
    "        X_test = test.drop(['Customers', 'Sales'], axis=1)\n",
    "        y_test = test['Sales']\n",
    "\n",
    "        # model\n",
    "        m = model.fit(X_train, y_train)\n",
    "\n",
    "        # prediction\n",
    "        y_pred = m.predict(X_test)\n",
    "\n",
    "        # performance\n",
    "        m_result = ml_error(model_name, y_test, y_pred)\n",
    "\n",
    "        # store performance of each kfold iteration\n",
    "        mae_list.append(m_result['MAE'])\n",
    "        mape_list.append(m_result['MAPE'])\n",
    "        rmse_list.append(m_result['RMSE'])\n",
    "\n",
    "    return pd.DataFrame( {'Model Name': model_name,\n",
    "                          'MAE CV': np.round( np.mean( mae_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mae_list ), 2 ).astype( str ),\n",
    "                          'MAPE CV': np.round( np.mean( mape_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( mape_list ), 2 ).astype( str ),\n",
    "                          'RMSE CV': np.round( np.mean( rmse_list ), 2 ).astype( str ) + ' +/- ' + np.round( np.std( rmse_list ), 2 ).astype( str ) }, index=[0] )\n",
    "\n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    \n",
    "    display(HTML('<style>.container { width:100% !important; }</style>'))\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "    sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesKFold:\n",
    "    \"\"\" A cross-validation generator specifically created for time series \n",
    "    containing a 'Date' column with frequency in days.\n",
    "\n",
    "    Provides train/test indices to split time series data samples in train/test\n",
    "    sets. Samples can be observed at irregular time intervals. Multiple samples per\n",
    "    timestamp are allowed.\n",
    "\n",
    "    This cross-validation object is a variation of class 'KFold'.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set. Note that unlike standard cross-validation methods,\n",
    "    successive training sets are supersets of those that come before them.\n",
    "\n",
    "    It should be used inside a pipeline that drops the 'Date' column during \n",
    "    preprocessing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "\n",
    "    test_size : int, default=None\n",
    "        Used to limit the size of the test set. Default is 42 days, or 6 weeks. \n",
    "        \n",
    "    gap : int, default=0\n",
    "        Number of DAYS to exclude from the end of each train set before\n",
    "        the test set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=5, test_size=42, gap=0):\n",
    "        self.n_splits = n_splits\n",
    "        self.test_size = test_size\n",
    "        self.gap = gap\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        test_size = self.test_size\n",
    "        gap = self.gap\n",
    "\n",
    "        X.index = np.arange(X.shape[0])\n",
    "\n",
    "        for k in range(1, n_folds):\n",
    "\n",
    "            test_start_date = X['Date'].max() - datetime.timedelta(days= k * test_size)\n",
    "            test_end_date = X['Date'].max() - datetime.timedelta(days= (k-1) * test_size)\n",
    "\n",
    "            train_end_date = test_start_date - datetime.timedelta(days=gap)\n",
    "\n",
    "            train_index = X[X['Date'] < train_end_date].index.values\n",
    "            test_index = X[(X['Date'] >= test_start_date) & (X['Date'] <= test_end_date)].index.values\n",
    "\n",
    "            yield train_index, test_index\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 844338\n",
      "Number of columns: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>542033</th>\n",
       "      <td>929</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-03</td>\n",
       "      <td>8709</td>\n",
       "      <td>954</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>4820.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store  DayOfWeek       Date  Sales  Customers  Open  Promo StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear PromoInterval\n",
       "542033    929          1 2014-03-03   8709        954     1      1            0              0         a          c               4820.0                        9.0                    2013.0       0              NaN              NaN           NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_raw = pd.read_csv('/Users/lucasstelmastchuk/Documents/repos/rossman_sales/data/train.csv', low_memory=False)\n",
    "df_store_raw = pd.read_csv('/Users/lucasstelmastchuk/Documents/repos/rossman_sales/data/store.csv', low_memory=False)\n",
    "\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how='left', on='Store')\n",
    "\n",
    "df = df_raw.copy()\n",
    "df = df[df['Open'] == 1]\n",
    "df = df[df['Sales'] > 0]\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "X_train = df.drop(['Sales', 'Customers'], axis=1).copy()\n",
    "y_train = df['Sales'].copy()\n",
    "\n",
    "print(f'Number of rows: {df.shape[0]}')\n",
    "print(f'Number of columns: {df.shape[1]}')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
       "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
       "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
       "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
       "       'Promo2SinceYear', 'PromoInterval'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>14130.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>7520.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek       Date  Open  Promo StateHoliday  SchoolHoliday StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear    PromoInterval\n",
       "0      1          4 2015-09-17   1.0      1            0              0         c          a               1270.0                        9.0                    2008.0       0              NaN              NaN              NaN\n",
       "1      3          4 2015-09-17   1.0      1            0              0         a          a              14130.0                       12.0                    2006.0       1             14.0           2011.0  Jan,Apr,Jul,Oct\n",
       "2      7          4 2015-09-17   1.0      1            0              0         a          c              24000.0                        4.0                    2013.0       0              NaN              NaN              NaN\n",
       "3      8          4 2015-09-17   1.0      1            0              0         a          a               7520.0                       10.0                    2014.0       0              NaN              NaN              NaN\n",
       "4      9          4 2015-09-17   1.0      1            0              0         a          c               2030.0                        8.0                    2000.0       0              NaN              NaN              NaN"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales_test = pd.read_csv('/Users/lucasstelmastchuk/Documents/repos/rossman_sales/data/test.csv', low_memory=False)\n",
    "df_raw_test = pd.merge(df_sales_test, df_store_raw, how='left', on='Store')\n",
    "X_test = df_raw_test.drop(['Id'], axis=1).copy()\n",
    "X_test['Date'] = pd.to_datetime(X_test['Date'])\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        self.competition_open_since_month_imputer = SimpleImputer(strategy='median').fit(X[['CompetitionOpenSinceMonth']])\n",
    "        self.competition_open_since_year_imputer = SimpleImputer(strategy='median').fit(X[['CompetitionOpenSinceYear']])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "\n",
    "        # CHANGING COLUMN NAMES TO SNAKE_CASE\n",
    "        cols_old = X.columns\n",
    "        snakecase = lambda x: inflection.underscore(x)\n",
    "        cols_new = list(map(snakecase, cols_old))\n",
    "        X.columns = cols_new\n",
    "\n",
    "        # FILLING IN MISSING VALUES\n",
    "        # Maximum competition distance is 75,860 meters. Considering that missing values are probably related to stores with\n",
    "        # no competition nearby, these stores will get the value 200,000 meters to indicate that competitors are far away.      \n",
    "        X['competition_distance'] = X['competition_distance'].apply(lambda x: 200000.0 if math.isnan(x) else x)\n",
    "\n",
    "        # Imputation of the median competition opening month and year for stores with no information about competition opening date.\n",
    "        # Note that missing values here do not represent absence of competition, but absence of information about competition opening date,\n",
    "        # as competion distance have very few missing values.\n",
    "        X['competition_open_since_month'] = self.competition_open_since_month_imputer.transform(X[['competition_open_since_month']])\n",
    "        X['competition_open_since_year'] = self.competition_open_since_year_imputer.transform(X[['competition_open_since_year']])\n",
    "\n",
    "        # Missing values for start of promo2 are linked to stores that do not participate in this second type of promotion at any given year.\n",
    "        # Missing values will be replaced with the current date so that the total elapsed time for these stores since the start of the \n",
    "        # promotion 2 will always be zero 0 (see feature engineering section).\n",
    "        X['promo2_since_week'] = X.apply(lambda x: x['date'].week if math.isnan(x['promo2_since_week']) else x['promo2_since_week'], axis=1)\n",
    "        X['promo2_since_year'] = X.apply(lambda x: x['date'].year if math.isnan(x['promo2_since_year']) else x['promo2_since_year'], axis=1)\n",
    "\n",
    "        # CORRECTING DATA TYPES\n",
    "        X['competition_open_since_month'] = X['competition_open_since_month'].astype(int)\n",
    "        X['competition_open_since_year'] = X['competition_open_since_year'].astype(int)\n",
    "        X['promo2_since_week'] = X['promo2_since_week'].astype(int)\n",
    "        X['promo2_since_year'] = X['promo2_since_year'].astype(int)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,  cyclical_features=True):\n",
    "        self.cyclical_features = cyclical_features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _transform_promo_interval(self, x):\n",
    "            if x['promo_interval'] == 'Jan,Apr,Jul,Oct':\n",
    "                if x['date'].month in [1, 4, 7, 10]:\n",
    "                    return 1\n",
    "                elif x['date'].month in [2, 5, 8, 11]:\n",
    "                    return 2\n",
    "                elif x['date'].month in [3, 6, 9, 12]:\n",
    "                    return 3\n",
    "            elif x['promo_interval'] == 'Feb,May,Aug,Nov':\n",
    "                if x['date'].month in [2, 5, 8, 11]:\n",
    "                    return 1\n",
    "                elif x['date'].month in [3, 6, 9, 12]:\n",
    "                    return 2\n",
    "                elif x['date'].month in [1, 4, 7, 10]:\n",
    "                    return 3\n",
    "            elif x['promo_interval'] == 'Mar,Jun,Sept,Dec':\n",
    "                if x['date'].month in [3, 6, 9, 12]:\n",
    "                    return 1\n",
    "                elif x['date'].month in [1, 4, 7, 10]:\n",
    "                    return 2\n",
    "                elif x['date'].month in [2, 5, 8, 11]:\n",
    "                    return 3\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "    def _sin_transform(self, col, period):\n",
    "                return np.sin(2*np.pi*col/period)\n",
    "            \n",
    "    def _cos_transform(self, col, period):\n",
    "                return np.cos(2*np.pi*col/period)\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "\n",
    "        # Extract features from date column\n",
    "        X['month'] = X['date'].dt.month\n",
    "        X['day_of_month'] = X['date'].dt.day\n",
    "        X['week_of_year'] = X['date'].dt.weekofyear\n",
    "        X['is_weekend'] = X['date'].dt.weekday > 4\n",
    "        X['is_weekend'] = X['is_weekend'].astype(int)\n",
    "        \n",
    "        # Combine year and month of competition opening and then calculate the elapsed time in months since competition opened.\n",
    "        X['competition_since_date'] = X.apply(lambda x: datetime.datetime(year=x['competition_open_since_year'],\n",
    "                                                                            month=x['competition_open_since_month'],\n",
    "                                                                            day=1), axis=1)\n",
    "        X['months_since_competition_opened'] = ((X['date'] - X['competition_since_date'])/pd.Timedelta('30 days')).astype(int)\n",
    "        X['months_since_competition_opened'] = X['months_since_competition_opened'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "        # promo since\n",
    "        X['promo2_since_date'] = X['promo2_since_year'].astype(str) + '-' + X['promo2_since_week'].astype(str)\n",
    "        X['promo2_since_date'] = X['promo2_since_date'].apply(lambda x: datetime.datetime.strptime(x + '-0', '%Y-%W-%w'))\n",
    "        X['weeks_since_promo2_started'] = ((X['date'] - X['promo2_since_date'])/pd.Timedelta('7 days')).astype(int)\n",
    "        X['weeks_since_promo2_started'] = X['weeks_since_promo2_started'].apply(lambda x: 0 if x < 0 else x)\n",
    "\n",
    "        # promo interval\n",
    "        X['promo_interval'] = X[['date', 'promo_interval']].apply(lambda y: self._transform_promo_interval(y), axis=1)\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        X.drop(['date','open', 'competition_open_since_month', 'competition_open_since_year', \n",
    "                'promo2_since_week', 'promo2_since_year', 'competition_since_date', 'promo2_since_date'], \n",
    "                axis=1, inplace=True)\n",
    "\n",
    "        # Add cyclical features\n",
    "        if self.cyclical_features:\n",
    "            \n",
    "            X['sin_month'] = self._sin_transform(X['month'], 12)\n",
    "            X['cos_month'] = self._cos_transform(X['month'], 12)\n",
    "            \n",
    "            X['sin_day_of_month'] = self._sin_transform(X['day_of_month'], 30)\n",
    "            X['cos_day_of_month'] = self._cos_transform(X['day_of_month'], 30)\n",
    "\n",
    "            X['sin_day_of_week'] = self._sin_transform(X['day_of_week'], 7)\n",
    "            X['cos_day_of_week'] = self._cos_transform(X['day_of_week'], 7)\n",
    "\n",
    "\n",
    "            X['sin_week_of_year'] = self._sin_transform(X['month'], 52)\n",
    "            X['cos_week_of_year'] = self._cos_transform(X['month'], 52)\n",
    "  \n",
    "            X.drop(['month', 'day_of_month', 'day_of_week', 'week_of_year'], axis=1, inplace=True)\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.competition_distance_scaler = RobustScaler().fit(X[['competition_distance']])\n",
    "        self.months_since_competition_opened_scaler = RobustScaler().fit(X[['months_since_competition_opened']])\n",
    "        self.weeks_since_promo2_started_scaler = RobustScaler().fit(X[['weeks_since_promo2_started']])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "\n",
    "        # SCALING NUMERICAL FEATURES\n",
    "        X['competition_distance'] = self.competition_distance_scaler.transform(X[['competition_distance']]).ravel()\n",
    "        X['months_since_competition_opened'] = self.months_since_competition_opened_scaler.transform(X[['months_since_competition_opened']]).ravel()\n",
    "        X['weeks_since_promo2_started'] = self.weeks_since_promo2_started_scaler.transform(X[['weeks_since_promo2_started']]).ravel()\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        self.state_holiday_encoder = OneHotEncoder(handle_unknown='ignore').fit(X[['state_holiday']])\n",
    "        self.state_holiday_new_columns = self.state_holiday_encoder.get_feature_names_out()\n",
    "\n",
    "        self.store_type_encoder = OneHotEncoder(handle_unknown='ignore').fit(X[['store_type']])\n",
    "        self.store_type_new_columns = self.store_type_encoder.get_feature_names_out()\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        X = X.copy()\n",
    "\n",
    "        # ENCODING CATEGORICAL FEATURES\n",
    "        X['assortment'] = X['assortment'].map({'a': 1, 'b': 2, 'c': 3})\n",
    "        X['state_holiday'] = X['state_holiday'].map({'a': 'public_holiday', 'b': 'easter', 'c': 'christmas', '0': 'not_holiday'})\n",
    "\n",
    "        state_holiday_encoded = pd.DataFrame(self.state_holiday_encoder.transform(X[['state_holiday']]).toarray(), columns=self.state_holiday_new_columns, index=X.index)\n",
    "\n",
    "        store_type_encoded = pd.DataFrame(self.store_type_encoder.transform(X[['store_type']]).toarray(), columns=self.store_type_new_columns, index=X.index)\n",
    "\n",
    "        X = pd.concat([X, state_holiday_encoded, store_type_encoded], axis=1).drop(['store_type', 'state_holiday'], axis=1)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('data_frame_cleaner', DataFrameCleaner()),\n",
    "                             ('attributes_adder', AttributesAdder()),\n",
    "                             ('scaler', Scaler()),\n",
    "                             ('encoder', Encoder()),\n",
    "                             ('feature_selection', SelectPercentile(mutual_info_regression, percentile=65)),\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = pipeline.fit_transform(X_train, y_train)\n",
    "df_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = pd.DataFrame(df_selected, columns=pipeline[-1].get_feature_names_out())\n",
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;data_frame_cleaner&#x27;, DataFrameCleaner()),\n",
       "                (&#x27;attributes_adder&#x27;, AttributesAdder()), (&#x27;scaler&#x27;, Scaler()),\n",
       "                (&#x27;encoder&#x27;, Encoder()),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 SelectPercentile(percentile=65,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x7f9f12cc85e0&gt;)),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;data_frame_cleaner&#x27;, DataFrameCleaner()),\n",
       "                (&#x27;attributes_adder&#x27;, AttributesAdder()), (&#x27;scaler&#x27;, Scaler()),\n",
       "                (&#x27;encoder&#x27;, Encoder()),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 SelectPercentile(percentile=65,\n",
       "                                  score_func=&lt;function mutual_info_regression at 0x7f9f12cc85e0&gt;)),\n",
       "                (&#x27;model&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DataFrameCleaner</label><div class=\"sk-toggleable__content\"><pre>DataFrameCleaner()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AttributesAdder</label><div class=\"sk-toggleable__content\"><pre>AttributesAdder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Scaler</label><div class=\"sk-toggleable__content\"><pre>Scaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Encoder</label><div class=\"sk-toggleable__content\"><pre>Encoder()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectPercentile</label><div class=\"sk-toggleable__content\"><pre>SelectPercentile(percentile=65,\n",
       "                 score_func=&lt;function mutual_info_regression at 0x7f9f12cc85e0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('data_frame_cleaner', DataFrameCleaner()),\n",
       "                ('attributes_adder', AttributesAdder()), ('scaler', Scaler()),\n",
       "                ('encoder', Encoder()),\n",
       "                ('feature_selection',\n",
       "                 SelectPercentile(percentile=65,\n",
       "                                  score_func=<function mutual_info_regression at 0x7f9f12cc85e0>)),\n",
       "                ('model', LinearRegression())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_pipeline = Pipeline(steps=[('data_frame_cleaner', DataFrameCleaner()),\n",
    "                                             ('attributes_adder', AttributesAdder()),\n",
    "                                             ('scaler', Scaler()),\n",
    "                                             ('encoder', Encoder()),\n",
    "                                             ('feature_selection', SelectPercentile(mutual_info_regression, percentile=65)),\n",
    "                                             ('model', LinearRegression())\n",
    "                                             ])\n",
    "linear_regression_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_pipeline.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(linear_regression_pipeline, X_train, y_train, scoring='neg_root_mean_squared_error', cv=TimeSeriesKFold(n_splits=5), error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2680.3013447118474"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_month\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceMonth\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/lucasstelmastchuk/opt/anaconda3/envs/ds_em_producao_lucas1/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- competition_open_since_year\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- CompetitionOpenSinceYear\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/var/folders/x7/b7jchjl54wsgp7ngc6r0wmpm0000gn/T/ipykernel_69463/1544349638.py:46: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(linear_regression_pipeline, X_train, y_train,\n",
    "                            scoring=['neg_mean_absolute_error', 'neg_mean_absolute_percentage_error','neg_root_mean_squared_error'],\n",
    "                            cv=TimeSeriesKFold(n_splits=5), error_score='raise', n_jobs=-1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1930.4877876671515\n",
      "-0.30654669990754435\n",
      "-2676.4187551911664\n"
     ]
    }
   ],
   "source": [
    "print(cv_results['test_neg_mean_absolute_error'].mean())\n",
    "print(cv_results['test_neg_mean_absolute_percentage_error'].mean())\n",
    "print(cv_results['test_neg_root_mean_squared_error'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>MAE CV</th>\n",
       "      <th>MAPE CV</th>\n",
       "      <th>RMSE CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>1937.25 +/- 103.32</td>\n",
       "      <td>0.31 +/- 0.01</td>\n",
       "      <td>2681.29 +/- 174.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model Name              MAE CV        MAPE CV             RMSE CV\n",
       "0  LinearRegression  1937.25 +/- 103.32  0.31 +/- 0.01  2681.29 +/- 174.77"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance\n",
    "lr_result_cv = cross_validation(df, 5, 'LinearRegression', linear_regression_pipeline, verbose=False)\n",
    "lr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "lrr = Lasso(alpha=0.01)\n",
    "tlrr = TransformedTargetRegressor(lrr, func=np.log1p, inverse_func=np.expm1) \n",
    "lrr_pipeline = make_pipeline(clean_df_transformer, add_features_transformer, features_transformer, tlrr)\n",
    "\n",
    "# performance\n",
    "lrr_result_cv = cross_validation(df, 5, 'Lasso', tlrr_pipeline, verbose=False )\n",
    "lrr_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "trf = TransformedTargetRegressor(rf, func=np.log1p, inverse_func=np.expm1) \n",
    "trf_pipeline = make_pipeline(clean_df_transformer, add_features_transformer, features_transformer, trf)\n",
    "\n",
    "# performance\n",
    "rf_result_cv = cross_validation(df, 5, 'Random Forest', trf_pipeline, verbose=False)\n",
    "rf_result_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf_pipeline[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "xgb_regressor = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                                  n_estimators=1000, \n",
    "                                  eta=0.01, \n",
    "                                  max_depth=10, \n",
    "                                  subsample=0.7,\n",
    "                                  colsample_bytree=0.9 )\n",
    "t_xgb_regressor = TransformedTargetRegressor(xgb_regressor, func=np.log1p, inverse_func=np.expm1) \n",
    "xgb_pipeline = make_pipeline(clean_df_transformer, add_features_transformer, features_transformer, t_xgb_regressor)\n",
    "\n",
    "# performance\n",
    "xgb_result_cv = cross_validation(df, 5, 'XGBoost', xgb_pipeline, verbose=False)\n",
    "xgb_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_result_cv = pd.concat([lr_result_cv, lrr_result_cv, rf_result_cv, xgb_result_cv])\n",
    "models_result_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.295487Z",
     "start_time": "2020-01-08T23:45:33.289860Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "   'n_estimators': [1500, 1700, 2500, 3000, 3500],\n",
    "   'eta': [0.01, 0.03],\n",
    "   'max_depth': [3, 5, 9],\n",
    "   'subsample': [0.1, 0.5, 0.7],\n",
    "   'colsample_bytree': [0.3, 0.7, 0.9],\n",
    "   'min_child_weight': [3, 8, 15]\n",
    "       }\n",
    "\n",
    "MAX_EVAL = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.311093Z",
     "start_time": "2020-01-08T23:45:33.301202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_result = pd.DataFrame()\n",
    "\n",
    "for i in range(MAX_EVAL):\n",
    "   # choose values for parameters randomly\n",
    "   hp = {k:random.sample(v,1)[0] for k, v in param.items()}\n",
    "   print(hp)\n",
    "   \n",
    "   # model\n",
    "   model_xgb = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                                 n_estimators=hp['n_estimators'], \n",
    "                                 eta=hp['eta'], \n",
    "                                 max_depth=hp['max_depth'], \n",
    "                                 subsample=hp['subsample'],\n",
    "                                 colsample_bytree=hp['colsample_bytree'],\n",
    "                                 min_child_weight=hp['min_child_weight'] )\n",
    "   transformed_xgb_regressor = TransformedTargetRegressor(model_xgb, func=np.log1p, inverse_func=np.expm1) \n",
    "   xgb_pipeline_tuning = make_pipeline(clean_df_transformer, add_features_transformer, features_transformer, transformed_xgb_regressor)\n",
    "   \n",
    "   # performance\n",
    "   result = cross_validation(df, 5, 'XGBoost Regressor', xgb_pipeline_tuning, verbose=False)\n",
    "   final_result = pd.concat([final_result, result])\n",
    "       \n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-08T23:45:33.348773Z",
     "start_time": "2020-01-08T23:45:33.344536Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param_tuned = {\n",
    "    'n_estimators': 1700,\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 9,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 8 \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T01:16:23.481635Z",
     "start_time": "2020-01-08T23:45:33.355270Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "xgb_tuned = xgb.XGBRegressor( objective='reg:squarederror',\n",
    "                                    n_estimators=param_tuned['n_estimators'], \n",
    "                                    eta=param_tuned['eta'], \n",
    "                                    max_depth=param_tuned['max_depth'], \n",
    "                                    subsample=param_tuned['subsample'],\n",
    "                                    colsample_bytree=param_tuned['colsample_bytree'],\n",
    "                                    min_child_weight=param_tuned['min_child_weight'])\n",
    "model_xgb_tuned = TransformedTargetRegressor(xgb_tuned, func=np.log1p, inverse_func=np.expm1) \n",
    "xgb_pipeline_tuned = make_pipeline(clean_df_transformer, add_features_transformer, features_transformer, model_xgb_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['Date'] < '2015-06-19']\n",
    "test = df[df['Date'] >= '2015-06-19']\n",
    "\n",
    "# train\n",
    "X_train = train.drop(['Customers', 'Sales'], axis=1)\n",
    "y_train = train['Sales']\n",
    "\n",
    "# validation\n",
    "X_test = test.drop(['Customers', 'Sales'], axis=1)\n",
    "y_test = test['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipeline_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_pipeline_tuned.predict(X_test)\n",
    "\n",
    "xgb_result_tuned = ml_error('XGBoost Regressor', y_test, y_pred)\n",
    "xgb_result_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_predictions_next_six_weeks = pd.DataFrame({'store':X_test['store'], 'sales':y_test, 'sales_prediction':y_pred})\n",
    "total_sales_predictions_per_store = sales_predictions_next_six_weeks.groupby('store').sum()\n",
    "mae = sales_predictions_next_six_weeks.groupby('store').apply(lambda x: mean_absolute_error( x['sales'], x['sales_prediction'])).reset_index().rename(columns={0:'MAE'})\n",
    "mape = sales_predictions_next_six_weeks.groupby('store').apply(lambda x: mean_absolute_percentage_error( x['sales'], x['sales_prediction'])).reset_index().rename(columns={0:'MAPE'})\n",
    "\n",
    "# Merge\n",
    "aux1 = pd.merge(mae, mape, how='inner', on='store')\n",
    "aux2 = pd.merge(aux1, total_sales_predictions_per_store, how='inner', on='store')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.scatterplot(x='store', y='MAPE', data=aux2)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.scatterplot(x='store', y='MAE', data=aux2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales_prediction = sales_predictions_next_six_weeks['sales_prediction'].sum()\n",
    "best_scenario = total_sales_prediction + xgb_result_tuned['MAE'].values[0]\n",
    "worst_scenario = total_sales_prediction - xgb_result_tuned['MAE'].values[0]\n",
    "\n",
    "scenarios = pd.DataFrame({'Scenario':['Total Sales Prediction', 'Worst Scenario', 'Best Scenario'],\n",
    "                'Value':[total_sales_prediction, worst_scenario, best_scenario]})\n",
    "\n",
    "scenarios['Value'] = scenarios['Value'].map('R${:,.2f}'.format)\n",
    "scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({'date':X_test['date'], 'store':X_test['store'], 'sales':y_test, 'sales_prediction':y_pred})\n",
    "df_results['residual'] = df_results['sales'] - df_results['sales_prediction']\n",
    "df_results['error_rate'] = df_results['sales_prediction']/df_results['sales']\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "sns.lineplot( x='date', y='sales', data=df_results, label='SALES')\n",
    "sns.lineplot( x='date', y='sales_prediction', data=df_results, label='PREDICTIONS')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.lineplot(x='date', y='error_rate', data=df_results)\n",
    "plt.axhline(1, linestyle='--')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.distplot(df_results['residual'])\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(df_results['sales_prediction'], df_results['residual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ds_em_producao_lucas1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "320c292c85c5354cc01e85ad0e828ca2ea3cc806ed1a4aeb7ff310b2c2042592"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
